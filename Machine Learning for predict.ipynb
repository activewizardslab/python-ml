{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "1. Import packages and functions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import time\n",
      "import datetime\n",
      "import numpy as np\n",
      "import re\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.metrics import roc_auc_score, make_scorer\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import svm\n",
      "from sklearn.metrics import accuracy_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "2. Load data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv(\"Introduction Matches - UPDATE 20150714.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Match: ID</th>\n",
        "      <th># Count Factors</th>\n",
        "      <th># Age vs Job</th>\n",
        "      <th># Customers vs Account</th>\n",
        "      <th># Customers vs Job</th>\n",
        "      <th># Industries vs Account</th>\n",
        "      <th># Industries vs Job</th>\n",
        "      <th># Loyalty vs Account</th>\n",
        "      <th># Pedigree vs Account</th>\n",
        "      <th># Roles vs Job</th>\n",
        "      <th>...</th>\n",
        "      <th>Lion Experience Customer (Weighted)</th>\n",
        "      <th>Introduction (Tracker): # Weeks Alive</th>\n",
        "      <th>Introduction (Tracker): Date to Screened</th>\n",
        "      <th>Introduction (Tracker): Date to Hired</th>\n",
        "      <th>Introduction to Screen?</th>\n",
        "      <th>Introduction to Meeting?</th>\n",
        "      <th>Introduction to Offer?</th>\n",
        "      <th>Introduction to Hire?</th>\n",
        "      <th>Introduction Alive 3 Weeks?</th>\n",
        "      <th>DO NOT USE (Match Failed?)</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>a0QF000000WAlbd</td>\n",
        "      <td>9</td>\n",
        "      <td>9</td>\n",
        "      <td>5</td>\n",
        "      <td>0</td>\n",
        "      <td>10</td>\n",
        "      <td>10</td>\n",
        "      <td>2</td>\n",
        "      <td>7</td>\n",
        "      <td>9</td>\n",
        "      <td>...</td>\n",
        "      <td>0.3</td>\n",
        "      <td>0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>a0QF000000BbI4j</td>\n",
        "      <td>8</td>\n",
        "      <td>9</td>\n",
        "      <td>10</td>\n",
        "      <td>9</td>\n",
        "      <td>4</td>\n",
        "      <td>10</td>\n",
        "      <td>7</td>\n",
        "      <td>NaN</td>\n",
        "      <td>9</td>\n",
        "      <td>...</td>\n",
        "      <td>2.3</td>\n",
        "      <td>2</td>\n",
        "      <td>12/18/13</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>a0QF000000WGYPU</td>\n",
        "      <td>4</td>\n",
        "      <td>5</td>\n",
        "      <td>NaN</td>\n",
        "      <td>10</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>9</td>\n",
        "      <td>...</td>\n",
        "      <td>NaN</td>\n",
        "      <td>3</td>\n",
        "      <td>9/18/14</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>a0QF000000BbsJ8</td>\n",
        "      <td>9</td>\n",
        "      <td>8</td>\n",
        "      <td>10</td>\n",
        "      <td>10</td>\n",
        "      <td>10</td>\n",
        "      <td>10</td>\n",
        "      <td>1</td>\n",
        "      <td>3</td>\n",
        "      <td>9</td>\n",
        "      <td>...</td>\n",
        "      <td>0.8</td>\n",
        "      <td>5</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>a0QF000000WNWWK</td>\n",
        "      <td>4</td>\n",
        "      <td>6</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>9</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>7</td>\n",
        "      <td>...</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1</td>\n",
        "      <td>9/24/14</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 35 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "         Match: ID  # Count Factors  # Age vs Job  # Customers vs Account  \\\n",
        "0  a0QF000000WAlbd                9             9                       5   \n",
        "1  a0QF000000BbI4j                8             9                      10   \n",
        "2  a0QF000000WGYPU                4             5                     NaN   \n",
        "3  a0QF000000BbsJ8                9             8                      10   \n",
        "4  a0QF000000WNWWK                4             6                     NaN   \n",
        "\n",
        "   # Customers vs Job  # Industries vs Account  # Industries vs Job  \\\n",
        "0                   0                       10                   10   \n",
        "1                   9                        4                   10   \n",
        "2                  10                      NaN                    0   \n",
        "3                  10                       10                   10   \n",
        "4                   0                      NaN                    9   \n",
        "\n",
        "   # Loyalty vs Account  # Pedigree vs Account  # Roles vs Job  \\\n",
        "0                     2                      7               9   \n",
        "1                     7                    NaN               9   \n",
        "2                   NaN                    NaN               9   \n",
        "3                     1                      3               9   \n",
        "4                   NaN                    NaN               7   \n",
        "\n",
        "              ...              Lion Experience Customer (Weighted)  \\\n",
        "0             ...                                              0.3   \n",
        "1             ...                                              2.3   \n",
        "2             ...                                              NaN   \n",
        "3             ...                                              0.8   \n",
        "4             ...                                              NaN   \n",
        "\n",
        "   Introduction (Tracker): # Weeks Alive  \\\n",
        "0                                      0   \n",
        "1                                      2   \n",
        "2                                      3   \n",
        "3                                      5   \n",
        "4                                      1   \n",
        "\n",
        "   Introduction (Tracker): Date to Screened  \\\n",
        "0                                       NaN   \n",
        "1                                  12/18/13   \n",
        "2                                   9/18/14   \n",
        "3                                       NaN   \n",
        "4                                   9/24/14   \n",
        "\n",
        "   Introduction (Tracker): Date to Hired  Introduction to Screen?  \\\n",
        "0                                    NaN                        0   \n",
        "1                                    NaN                        1   \n",
        "2                                    NaN                        1   \n",
        "3                                    NaN                        0   \n",
        "4                                    NaN                        1   \n",
        "\n",
        "   Introduction to Meeting?  Introduction to Offer?  Introduction to Hire?  \\\n",
        "0                         0                       0                      0   \n",
        "1                         1                       0                      0   \n",
        "2                         0                       0                      0   \n",
        "3                         0                       0                      0   \n",
        "4                         0                       0                      0   \n",
        "\n",
        "  Introduction Alive 3 Weeks?  DO NOT USE (Match Failed?)  \n",
        "0                           0                           0  \n",
        "1                           0                           0  \n",
        "2                           1                           0  \n",
        "3                           1                           0  \n",
        "4                           0                           0  \n",
        "\n",
        "[5 rows x 35 columns]"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "3. Data checking (density in percent) and preparation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Checking density\n",
      "n=df[\"Match: ID\"].count()\n",
      "for i in df[:]:\n",
      "       print df[i].dtypes, \"     \", (n-df[i].count())*100/n, \"     \", i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "object       0       Match: ID\n",
        "int64       0       # Count Factors\n",
        "float64       4       # Age vs Job\n",
        "float64       27       # Customers vs Account\n",
        "float64       34       # Customers vs Job\n",
        "float64       25       # Industries vs Account\n",
        "float64       34       # Industries vs Job\n",
        "float64       20       # Loyalty vs Account\n",
        "float64       40       # Pedigree vs Account\n",
        "float64       4       # Roles vs Job\n",
        "float64       18       # University vs Account\n",
        "float64       20       % Loyalty vs Team\n",
        "float64       3       % Loyalty vs Universe\n",
        "float64       40       % Pedigree vs Team\n",
        "float64       14       % Pedigree vs Universe\n",
        "float64       18       % University vs Team\n",
        "float64       3       % University vs Universe\n",
        "float64       5       + Position Tenure (Months)\n",
        "object       0       Job Experience (Years)\n",
        "int64       0       Deviation Denominator (Years)\n",
        "float64       0       Lion Experience Total\n",
        "float64       0       Lion Experience Role\n",
        "float64       23       Lion Experience Industry\n",
        "float64       4       Lion Experience Industry (Weighted)\n",
        "float64       23       Lion Experience Customer\n",
        "float64       6       Lion Experience Customer (Weighted)\n",
        "int64       0       Introduction (Tracker): # Weeks Alive\n",
        "object       47       Introduction (Tracker): Date to Screened\n",
        "object       95       Introduction (Tracker): Date to Hired\n",
        "int64       0       Introduction to Screen?\n",
        "int64       0       Introduction to Meeting?\n",
        "int64       0       Introduction to Offer?\n",
        "int64       0       Introduction to Hire?\n",
        "int64       0       Introduction Alive 3 Weeks?\n",
        "int64       0       DO NOT USE (Match Failed?)\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Transform data in Job Experience (Years) column\n",
      "def convertString (strintToConvert):\n",
      "    strintToConvert = str(strintToConvert)\n",
      "    strintToConvert = re.sub(r'[^0-9]','',strintToConvert)\n",
      "    if len(strintToConvert) == 0:\n",
      "        strintToConvert = \"0\"\n",
      "    return int(strintToConvert)\n",
      "\n",
      "df[\"Job Experience (Years)\"] = df[\"Job Experience (Years)\"].map(lambda s: convertString(s))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Transform data in Introduction (Tracker): Date to Screened and Introduction (Tracker): Date to Hired columns\n",
      "def transformDate (date):\n",
      "    if date == date:\n",
      "        date =int( time.mktime(datetime.datetime.strptime(str(date), \"%m/%d/%y\").timetuple()))\n",
      "    return date\n",
      "\n",
      "df[\"Introduction (Tracker): Date to Screened\"] = df[\"Introduction (Tracker): Date to Screened\"].map(lambda d: transformDate(d))\n",
      "df[\"Introduction (Tracker): Date to Hired\"] = df[\"Introduction (Tracker): Date to Hired\"].map(lambda d: transformDate(d))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Deleting non-information column Match: ID\n",
      "df = df.drop(['Match: ID'], 1)\n",
      "# Convert data type\n",
      "df = df.astype('float64')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Filling empty cells\n",
      "def ConvertNaNinMedian(SelValue, med):\n",
      "    if SelValue != SelValue:\n",
      "        SelValue = med\n",
      "    return SelValue\n",
      "\n",
      "for i in df[:]:\n",
      "    m=df[i].median()\n",
      "    df[i] = df[i].map(lambda x: ConvertNaNinMedian(x,m))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \u0421hecking full compliance\n",
      "for i in df[:]:\n",
      "       print df[i].dtypes, \"     \", (n-df[i].count())*100/n, \"     \", i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "float64       0       # Count Factors\n",
        "float64       0       # Age vs Job\n",
        "float64       0       # Customers vs Account\n",
        "float64       0       # Customers vs Job\n",
        "float64       0       # Industries vs Account\n",
        "float64       0       # Industries vs Job\n",
        "float64       0       # Loyalty vs Account\n",
        "float64       0       # Pedigree vs Account\n",
        "float64       0       # Roles vs Job\n",
        "float64       0       # University vs Account\n",
        "float64       0       % Loyalty vs Team\n",
        "float64       0       % Loyalty vs Universe\n",
        "float64       0       % Pedigree vs Team\n",
        "float64       0       % Pedigree vs Universe\n",
        "float64       0       % University vs Team\n",
        "float64       0       % University vs Universe\n",
        "float64       0       + Position Tenure (Months)\n",
        "float64       0       Job Experience (Years)\n",
        "float64       0       Deviation Denominator (Years)\n",
        "float64       0       Lion Experience Total\n",
        "float64       0       Lion Experience Role\n",
        "float64       0       Lion Experience Industry\n",
        "float64       0       Lion Experience Industry (Weighted)\n",
        "float64       0       Lion Experience Customer\n",
        "float64       0       Lion Experience Customer (Weighted)\n",
        "float64       0       Introduction (Tracker): # Weeks Alive\n",
        "float64       0       Introduction (Tracker): Date to Screened\n",
        "float64       0       Introduction (Tracker): Date to Hired\n",
        "float64       0       Introduction to Screen?\n",
        "float64       0       Introduction to Meeting?\n",
        "float64       0       Introduction to Offer?\n",
        "float64       0       Introduction to Hire?\n",
        "float64       0       Introduction Alive 3 Weeks?\n",
        "float64       0       DO NOT USE (Match Failed?)\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "4. Rolling data into a numpy array, and choose data for model applicationand split data on test/train"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = np.array(df[\"# Age vs Job\"].values.tolist())\n",
      "print y\n",
      "print\n",
      "\n",
      "df = df.drop([\"# Age vs Job\"], 1)\n",
      "X = np.array(df.values)\n",
      "print X"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 9.  9.  5. ...,  9.  5.  9.]\n",
        "\n",
        "[[  9.   5.   0. ...,   0.   0.   0.]\n",
        " [  8.  10.   9. ...,   0.   0.   0.]\n",
        " [  4.   0.  10. ...,   0.   1.   0.]\n",
        " ..., \n",
        " [  8.   0.   0. ...,   0.   1.   1.]\n",
        " [  5.   0.   0. ...,   0.   0.   1.]\n",
        " [  3.   0.   0. ...,   0.   0.   1.]]\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# split on trainset and testset\n",
      "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "5. Training and testing."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# Additional block for AUS calculation\n",
      "def get_roc(classifier, raw_X_train, raw_y_train, raw_X_test, raw_y_test):\n",
      "    X_train, X_test, y_train, y_test = raw_X_train, raw_X_test, raw_y_train, raw_y_test \n",
      "    #train_test_split(raw_X,raw_y, test_size=0.33, random_state=42)\n",
      "    classifier.fit(X_train, y_train)\n",
      "    P = classifier.predict_proba(X_test)\n",
      "    prediction = classifier.predict(X_test)\n",
      "    agg_roc = []\n",
      "    for i, c in enumerate(classifier.classes_):\n",
      "        if c == 1:\n",
      "            pass\n",
      "        else:\n",
      "            #print i, c, cls.classes_[i]\n",
      "            # for each class - http://joxi.ru/GrqdvNWfwdPaAz\n",
      "            predictions = [p[i] for p in P]\n",
      "            groundtruth = [1 if y1==classifier.classes_[i] else 0 for y1 in y_test]\n",
      "            roc = roc_auc_score(groundtruth, predictions)\n",
      "            agg_roc.append(roc)\n",
      "#            print \"roc of \", classifier.classes_[i], \" = \", roc\n",
      "    return agg_roc\n",
      "    #return -1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# Additional block for calculation medium\n",
      "def medium(arrauRoc):\n",
      "    medium=0\n",
      "    lenroc=0\n",
      "    for k in arrauRoc[:]:\n",
      "        medium=medium+k\n",
      "        lenroc=lenroc+1\n",
      "    medium=medium/lenroc\n",
      "    return medium"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# Open data file for writting AUC and Accuracy\n",
      "AllRoc = pd.DataFrame()\n",
      "AllRoc[\"roc of\"]=[0,2,3,4,5,6,7,8,9,10,'medium','Accuracy']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Random Forest Classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Calculation AUC and Accuracy for all considered parameters\n",
      "test_n_estimators=[10,50,100,150,200,250,300,350,400,450,500]\n",
      "for i in test_n_estimators[:]:\n",
      "    model = RandomForestClassifier(n_estimators=i)\n",
      "    clf=model.fit(Xtrain, ytrain)\n",
      "    ypred = clf.predict(Xtest)\n",
      "    roc = get_roc(clf,Xtrain,ytrain,Xtest, ytest)\n",
      "    AllRoc[\"Random Forest Classifier (n_estimator=\"+str(i)+\")\"]=roc+[medium(roc)]+[accuracy_score(ytest, ypred)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Calculation best combination of parameters\n",
      "paramRFC={'n_estimators':[10,50,100,150,200,250,300,350,400,450,500]}\n",
      "model = RandomForestClassifier()\n",
      "gridRFC = GridSearchCV(model, param_grid=paramRFC)\n",
      "clfRFC = gridRFC.fit(Xtrain, ytrain)\n",
      "best_n_estimators=clfRFC.best_estimator_.n_estimators"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Training classifier for best parameters and getting prediction\n",
      "clfRFC=RandomForestClassifier(n_estimators=best_n_estimators)\n",
      "clfRFC = clfRFC.fit(Xtrain, ytrain)\n",
      "ypredRFC = clfRFC.predict(Xtest)\n",
      "rocRFC = get_roc(clfRFC,Xtrain,ytrain,Xtest, ytest)\n",
      "AllRoc[\"Best Random Forest Classifier (n_estimators=\"+str(best_n_estimators)+\n",
      "       \")\"]=rocRFC+[medium(rocRFC)]+[accuracy_score(ytest, ypredRFC)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "SVM"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Training SVM\n",
      "clfSVM = svm.SVC(kernel='rbf', probability=True)\n",
      "clfSVM = clfSVM.fit(Xtrain, ytrain)\n",
      "ypredSVM = clfSVM.predict(Xtest)\n",
      "rocSVM = get_roc(clfSVM,Xtrain,ytrain,Xtest, ytest)\n",
      "AllRoc[\"Best SVM (kernel=rbf)\"]=rocSVM+[medium(rocSVM)]+[accuracy_score(ytest, ypredSVM)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Decision tree classifier."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Calculation AUC and Accuracy for all considered parameters\n",
      "test_criterion=[\"gini\", \"entropy\"]\n",
      "test_min_samples_split=[2, 10, 20]\n",
      "test_max_depth=[None, 2, 5, 10]\n",
      "test_min_samples_leaf=[1, 5, 10]\n",
      "test_max_leaf_nodes=[None, 5, 10, 20]\n",
      "for i in test_criterion[:]:\n",
      "    for j in test_min_samples_split[:]:\n",
      "        for k in test_max_depth[:]:\n",
      "            for l in test_min_samples_leaf[:]:\n",
      "                for m in test_max_leaf_nodes[:]:\n",
      "                    model = DecisionTreeClassifier(criterion=i,\n",
      "                                                   min_samples_split=j,\n",
      "                                                   max_depth=k,\n",
      "                                                   min_samples_leaf=l,\n",
      "                                                   max_leaf_nodes=m)\n",
      "                    clf=model.fit(Xtrain, ytrain)\n",
      "                    ypred = clf.predict(Xtest)\n",
      "                    roc = get_roc(clf,Xtrain,ytrain,Xtest, ytest)\n",
      "                    AllRoc[\"Decision Tree Classifier (criterion=\"+i+\n",
      "                           \", min_samples_split=\"+str(j)+\n",
      "                           \", max_depth=\"+str(k)+\n",
      "                           \", min_samples_leaf=\"+str(l)+\n",
      "                           \", max_leaf_nodes=\"+str(m)+\")\"]=roc+[medium(roc)]+[accuracy_score(ytest, ypred)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# Calculation best combination of parameters\n",
      "paramDTC = {\"criterion\": [\"gini\", \"entropy\"],\n",
      "            \"min_samples_split\": [2, 10, 20],\n",
      "            \"max_depth\": [None, 2, 5, 10],\n",
      "            \"min_samples_leaf\": [1, 5, 10],\n",
      "            \"max_leaf_nodes\": [None, 5, 10, 20]}\n",
      "model = DecisionTreeClassifier()\n",
      "gridDTC = GridSearchCV(model, param_grid=paramDTC)\n",
      "clfDTC = gridDTC.fit(Xtrain, ytrain)\n",
      "best_criterion=clfDTC.best_estimator_.criterion\n",
      "best_min_samples_split=clfDTC.best_estimator_.min_samples_split\n",
      "best_max_depth=clfDTC.best_estimator_.max_depth\n",
      "best_min_samples_leaf=clfDTC.best_estimator_.min_samples_leaf\n",
      "best_max_leaf_nodes=clfDTC.best_estimator_.max_leaf_nodes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Training classifier for best parameters and getting prediction\n",
      "clfDTC = DecisionTreeClassifier(criterion=best_criterion,\n",
      "                                min_samples_split=best_min_samples_split,\n",
      "                                max_depth=best_max_depth,\n",
      "                                min_samples_leaf=best_min_samples_leaf,\n",
      "                                max_leaf_nodes=best_max_leaf_nodes)\n",
      "clfDTC.fit(Xtrain, ytrain)\n",
      "ypredDTC = clfDTC.predict(Xtest)\n",
      "rocDTC = get_roc(clfDTC,Xtrain,ytrain,Xtest, ytest)\n",
      "AllRoc[\"Best Decision Tree Classifier (criterion=\"+best_criterion+\n",
      "                           \", min_samples_split=\"+str(best_min_samples_split)+\n",
      "                           \", max_depth=\"+str(best_max_depth)+\n",
      "                           \", min_samples_leaf=\"+str(best_min_samples_leaf)+\n",
      "                           \", max_leaf_nodes=\"+str(best_max_leaf_nodes)+\n",
      "                           \")\"]=rocDTC+[medium(rocDTC)]+[accuracy_score(ytest, ypredDTC)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Logistic Regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Calculation AUC and Accuracy for all considered parameters\n",
      "testC=[0.1, 1, 10, 100, 1000]\n",
      "for j in testC[:]:\n",
      "    model = LogisticRegression(C=j)\n",
      "    clf=model.fit(Xtrain, ytrain)\n",
      "    ypred = clf.predict(Xtest)\n",
      "    roc = get_roc(clf,Xtrain,ytrain,Xtest, ytest)\n",
      "    AllRoc[\"Logistic Regression (C=\"+str(j)+\")\"]=roc+[medium(roc)]+[accuracy_score(ytest, ypred)]"
     ],
     "language": "python",
     "metadata": {
      "scrolled": true
     },
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Calculation best combination of parameters\n",
      "paramLogReg = {'C':[0.1, 1, 10, 100, 1000]}\n",
      "model = LogisticRegression()\n",
      "gridLogReg = GridSearchCV(model, param_grid=paramLogReg)\n",
      "clfLogReg = gridLogReg.fit(Xtrain, ytrain)\n",
      "best_C_LogReg=clfLogReg.best_estimator_.C"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Training classifier for best parameters and getting prediction\n",
      "clfLogReg = LogisticRegression(C=best_C_LogReg)\n",
      "clfLogReg.fit(Xtrain, ytrain)\n",
      "ypredLogReg = clfLogReg.predict(Xtest)\n",
      "rocLogReg = get_roc(clfLogReg,Xtrain,ytrain,Xtest, ytest)\n",
      "AllRoc[\"Best Logistic Regression (C=\"+str(best_C_LogReg)+\")\"]=rocLogReg+[medium(rocLogReg)]+[accuracy_score(ytest, ypredLogReg)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Gradient Boosting Classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# Training Gradient Boosting Classifier\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "clfGBC = GradientBoostingClassifier()\n",
      "clfGBC.fit(Xtrain, ytrain)\n",
      "ypredGBC = clfGBC.predict(Xtest)\n",
      "rocGBC = get_roc(clfGBC,Xtrain,ytrain,Xtest, ytest)\n",
      "AllRoc[\"Best Gradient Boosting Classifier (kernel=rbf)\"]=rocGBC+[medium(rocGBC)]+[accuracy_score(ytest, ypredGBC)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "AllRoc.to_csv(\"Roc of all models.csv\", index=False)\n",
      "AllRoc[:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div>\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>roc of</th>\n",
        "      <th>Random Forest Classifier (n_estimator=10)</th>\n",
        "      <th>Random Forest Classifier (n_estimator=50)</th>\n",
        "      <th>Random Forest Classifier (n_estimator=100)</th>\n",
        "      <th>Random Forest Classifier (n_estimator=150)</th>\n",
        "      <th>Random Forest Classifier (n_estimator=200)</th>\n",
        "      <th>Random Forest Classifier (n_estimator=250)</th>\n",
        "      <th>Random Forest Classifier (n_estimator=300)</th>\n",
        "      <th>Random Forest Classifier (n_estimator=350)</th>\n",
        "      <th>Random Forest Classifier (n_estimator=400)</th>\n",
        "      <th>...</th>\n",
        "      <th>Decision Tree Classifier (criterion=entropy, min_samples_split=20, max_depth=10, min_samples_leaf=10, max_leaf_nodes=10)</th>\n",
        "      <th>Decision Tree Classifier (criterion=entropy, min_samples_split=20, max_depth=10, min_samples_leaf=10, max_leaf_nodes=20)</th>\n",
        "      <th>Best Decision Tree Classifier (criterion=entropy, min_samples_split=2, max_depth=None, min_samples_leaf=1, max_leaf_nodes=None)</th>\n",
        "      <th>Logistic Regression (C=0.1)</th>\n",
        "      <th>Logistic Regression (C=1)</th>\n",
        "      <th>Logistic Regression (C=10)</th>\n",
        "      <th>Logistic Regression (C=100)</th>\n",
        "      <th>Logistic Regression (C=1000)</th>\n",
        "      <th>Best Logistic Regression (C=0.1)</th>\n",
        "      <th>Best Gradient Boosting Classifier (kernel=rbf)</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>0</td>\n",
        "      <td>0.970997</td>\n",
        "      <td>0.991698</td>\n",
        "      <td>0.992953</td>\n",
        "      <td>0.992918</td>\n",
        "      <td>0.993183</td>\n",
        "      <td>0.993689</td>\n",
        "      <td>0.992762</td>\n",
        "      <td>0.988940</td>\n",
        "      <td>0.993361</td>\n",
        "      <td>...</td>\n",
        "      <td>0.898260</td>\n",
        "      <td>0.949773</td>\n",
        "      <td>0.965098</td>\n",
        "      <td>0.450795</td>\n",
        "      <td>0.450795</td>\n",
        "      <td>0.450795</td>\n",
        "      <td>0.450795</td>\n",
        "      <td>0.450795</td>\n",
        "      <td>0.450795</td>\n",
        "      <td>0.998870</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>2</td>\n",
        "      <td>0.874389</td>\n",
        "      <td>0.920174</td>\n",
        "      <td>0.931548</td>\n",
        "      <td>0.921879</td>\n",
        "      <td>0.939237</td>\n",
        "      <td>0.922956</td>\n",
        "      <td>0.941725</td>\n",
        "      <td>0.924774</td>\n",
        "      <td>0.927099</td>\n",
        "      <td>...</td>\n",
        "      <td>0.832577</td>\n",
        "      <td>0.893102</td>\n",
        "      <td>0.901925</td>\n",
        "      <td>0.534473</td>\n",
        "      <td>0.534473</td>\n",
        "      <td>0.534473</td>\n",
        "      <td>0.534473</td>\n",
        "      <td>0.534473</td>\n",
        "      <td>0.534473</td>\n",
        "      <td>0.928998</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>3</td>\n",
        "      <td>0.864497</td>\n",
        "      <td>0.948935</td>\n",
        "      <td>0.962835</td>\n",
        "      <td>0.972928</td>\n",
        "      <td>0.958151</td>\n",
        "      <td>0.973849</td>\n",
        "      <td>0.969104</td>\n",
        "      <td>0.969353</td>\n",
        "      <td>0.974457</td>\n",
        "      <td>...</td>\n",
        "      <td>0.823393</td>\n",
        "      <td>0.905480</td>\n",
        "      <td>0.979359</td>\n",
        "      <td>0.585344</td>\n",
        "      <td>0.585344</td>\n",
        "      <td>0.585344</td>\n",
        "      <td>0.585344</td>\n",
        "      <td>0.585344</td>\n",
        "      <td>0.585344</td>\n",
        "      <td>0.988991</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>4</td>\n",
        "      <td>0.904739</td>\n",
        "      <td>0.961256</td>\n",
        "      <td>0.972030</td>\n",
        "      <td>0.962350</td>\n",
        "      <td>0.972885</td>\n",
        "      <td>0.970296</td>\n",
        "      <td>0.974868</td>\n",
        "      <td>0.971187</td>\n",
        "      <td>0.976677</td>\n",
        "      <td>...</td>\n",
        "      <td>0.813888</td>\n",
        "      <td>0.900802</td>\n",
        "      <td>0.957493</td>\n",
        "      <td>0.519230</td>\n",
        "      <td>0.519230</td>\n",
        "      <td>0.519230</td>\n",
        "      <td>0.519230</td>\n",
        "      <td>0.519230</td>\n",
        "      <td>0.519230</td>\n",
        "      <td>0.983775</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>5</td>\n",
        "      <td>0.918605</td>\n",
        "      <td>0.963015</td>\n",
        "      <td>0.970536</td>\n",
        "      <td>0.967896</td>\n",
        "      <td>0.971173</td>\n",
        "      <td>0.971535</td>\n",
        "      <td>0.971396</td>\n",
        "      <td>0.970677</td>\n",
        "      <td>0.973456</td>\n",
        "      <td>...</td>\n",
        "      <td>0.885115</td>\n",
        "      <td>0.936381</td>\n",
        "      <td>0.977268</td>\n",
        "      <td>0.491515</td>\n",
        "      <td>0.491515</td>\n",
        "      <td>0.491515</td>\n",
        "      <td>0.491515</td>\n",
        "      <td>0.491515</td>\n",
        "      <td>0.491515</td>\n",
        "      <td>0.992001</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td>6</td>\n",
        "      <td>0.903538</td>\n",
        "      <td>0.959421</td>\n",
        "      <td>0.964862</td>\n",
        "      <td>0.964357</td>\n",
        "      <td>0.969129</td>\n",
        "      <td>0.969877</td>\n",
        "      <td>0.971009</td>\n",
        "      <td>0.966762</td>\n",
        "      <td>0.968252</td>\n",
        "      <td>...</td>\n",
        "      <td>0.795765</td>\n",
        "      <td>0.874392</td>\n",
        "      <td>0.985308</td>\n",
        "      <td>0.470888</td>\n",
        "      <td>0.470888</td>\n",
        "      <td>0.470888</td>\n",
        "      <td>0.470888</td>\n",
        "      <td>0.470888</td>\n",
        "      <td>0.470888</td>\n",
        "      <td>0.997386</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td>7</td>\n",
        "      <td>0.929675</td>\n",
        "      <td>0.966715</td>\n",
        "      <td>0.974844</td>\n",
        "      <td>0.972234</td>\n",
        "      <td>0.974171</td>\n",
        "      <td>0.974508</td>\n",
        "      <td>0.977119</td>\n",
        "      <td>0.973669</td>\n",
        "      <td>0.977069</td>\n",
        "      <td>...</td>\n",
        "      <td>0.843265</td>\n",
        "      <td>0.958637</td>\n",
        "      <td>0.989443</td>\n",
        "      <td>0.507250</td>\n",
        "      <td>0.507250</td>\n",
        "      <td>0.507250</td>\n",
        "      <td>0.507250</td>\n",
        "      <td>0.507250</td>\n",
        "      <td>0.507250</td>\n",
        "      <td>0.995595</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7</th>\n",
        "      <td>8</td>\n",
        "      <td>0.942117</td>\n",
        "      <td>0.982018</td>\n",
        "      <td>0.987997</td>\n",
        "      <td>0.983340</td>\n",
        "      <td>0.988194</td>\n",
        "      <td>0.987504</td>\n",
        "      <td>0.988761</td>\n",
        "      <td>0.987165</td>\n",
        "      <td>0.989087</td>\n",
        "      <td>...</td>\n",
        "      <td>0.690112</td>\n",
        "      <td>0.918442</td>\n",
        "      <td>0.987658</td>\n",
        "      <td>0.511605</td>\n",
        "      <td>0.511605</td>\n",
        "      <td>0.511605</td>\n",
        "      <td>0.511605</td>\n",
        "      <td>0.511605</td>\n",
        "      <td>0.511605</td>\n",
        "      <td>0.995521</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8</th>\n",
        "      <td>9</td>\n",
        "      <td>0.968431</td>\n",
        "      <td>0.987250</td>\n",
        "      <td>0.989118</td>\n",
        "      <td>0.987105</td>\n",
        "      <td>0.989533</td>\n",
        "      <td>0.990197</td>\n",
        "      <td>0.990580</td>\n",
        "      <td>0.989070</td>\n",
        "      <td>0.990375</td>\n",
        "      <td>...</td>\n",
        "      <td>0.817113</td>\n",
        "      <td>0.938582</td>\n",
        "      <td>0.999673</td>\n",
        "      <td>0.543008</td>\n",
        "      <td>0.543008</td>\n",
        "      <td>0.543008</td>\n",
        "      <td>0.543008</td>\n",
        "      <td>0.543008</td>\n",
        "      <td>0.543008</td>\n",
        "      <td>0.998788</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9</th>\n",
        "      <td>10</td>\n",
        "      <td>0.971729</td>\n",
        "      <td>0.986000</td>\n",
        "      <td>0.989204</td>\n",
        "      <td>0.987669</td>\n",
        "      <td>0.989219</td>\n",
        "      <td>0.989668</td>\n",
        "      <td>0.990724</td>\n",
        "      <td>0.988273</td>\n",
        "      <td>0.990569</td>\n",
        "      <td>...</td>\n",
        "      <td>0.837015</td>\n",
        "      <td>0.942484</td>\n",
        "      <td>0.995761</td>\n",
        "      <td>0.479785</td>\n",
        "      <td>0.479785</td>\n",
        "      <td>0.479785</td>\n",
        "      <td>0.479785</td>\n",
        "      <td>0.479785</td>\n",
        "      <td>0.479785</td>\n",
        "      <td>0.996628</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td>medium</td>\n",
        "      <td>0.924872</td>\n",
        "      <td>0.966648</td>\n",
        "      <td>0.973593</td>\n",
        "      <td>0.971268</td>\n",
        "      <td>0.974487</td>\n",
        "      <td>0.974408</td>\n",
        "      <td>0.976805</td>\n",
        "      <td>0.972987</td>\n",
        "      <td>0.976040</td>\n",
        "      <td>...</td>\n",
        "      <td>0.823650</td>\n",
        "      <td>0.921807</td>\n",
        "      <td>0.973899</td>\n",
        "      <td>0.509389</td>\n",
        "      <td>0.509389</td>\n",
        "      <td>0.509389</td>\n",
        "      <td>0.509389</td>\n",
        "      <td>0.509389</td>\n",
        "      <td>0.509389</td>\n",
        "      <td>0.987655</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td>Accuracy</td>\n",
        "      <td>0.690991</td>\n",
        "      <td>0.805234</td>\n",
        "      <td>0.822849</td>\n",
        "      <td>0.834927</td>\n",
        "      <td>0.833417</td>\n",
        "      <td>0.833417</td>\n",
        "      <td>0.847006</td>\n",
        "      <td>0.835430</td>\n",
        "      <td>0.832914</td>\n",
        "      <td>...</td>\n",
        "      <td>0.384499</td>\n",
        "      <td>0.571213</td>\n",
        "      <td>0.972823</td>\n",
        "      <td>0.230498</td>\n",
        "      <td>0.230498</td>\n",
        "      <td>0.230498</td>\n",
        "      <td>0.230498</td>\n",
        "      <td>0.230498</td>\n",
        "      <td>0.230498</td>\n",
        "      <td>0.950176</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>12 rows \u00d7 310 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "      roc of  Random Forest Classifier (n_estimator=10)  \\\n",
        "0          0                                   0.970997   \n",
        "1          2                                   0.874389   \n",
        "2          3                                   0.864497   \n",
        "3          4                                   0.904739   \n",
        "4          5                                   0.918605   \n",
        "5          6                                   0.903538   \n",
        "6          7                                   0.929675   \n",
        "7          8                                   0.942117   \n",
        "8          9                                   0.968431   \n",
        "9         10                                   0.971729   \n",
        "10    medium                                   0.924872   \n",
        "11  Accuracy                                   0.690991   \n",
        "\n",
        "    Random Forest Classifier (n_estimator=50)  \\\n",
        "0                                    0.991698   \n",
        "1                                    0.920174   \n",
        "2                                    0.948935   \n",
        "3                                    0.961256   \n",
        "4                                    0.963015   \n",
        "5                                    0.959421   \n",
        "6                                    0.966715   \n",
        "7                                    0.982018   \n",
        "8                                    0.987250   \n",
        "9                                    0.986000   \n",
        "10                                   0.966648   \n",
        "11                                   0.805234   \n",
        "\n",
        "    Random Forest Classifier (n_estimator=100)  \\\n",
        "0                                     0.992953   \n",
        "1                                     0.931548   \n",
        "2                                     0.962835   \n",
        "3                                     0.972030   \n",
        "4                                     0.970536   \n",
        "5                                     0.964862   \n",
        "6                                     0.974844   \n",
        "7                                     0.987997   \n",
        "8                                     0.989118   \n",
        "9                                     0.989204   \n",
        "10                                    0.973593   \n",
        "11                                    0.822849   \n",
        "\n",
        "    Random Forest Classifier (n_estimator=150)  \\\n",
        "0                                     0.992918   \n",
        "1                                     0.921879   \n",
        "2                                     0.972928   \n",
        "3                                     0.962350   \n",
        "4                                     0.967896   \n",
        "5                                     0.964357   \n",
        "6                                     0.972234   \n",
        "7                                     0.983340   \n",
        "8                                     0.987105   \n",
        "9                                     0.987669   \n",
        "10                                    0.971268   \n",
        "11                                    0.834927   \n",
        "\n",
        "    Random Forest Classifier (n_estimator=200)  \\\n",
        "0                                     0.993183   \n",
        "1                                     0.939237   \n",
        "2                                     0.958151   \n",
        "3                                     0.972885   \n",
        "4                                     0.971173   \n",
        "5                                     0.969129   \n",
        "6                                     0.974171   \n",
        "7                                     0.988194   \n",
        "8                                     0.989533   \n",
        "9                                     0.989219   \n",
        "10                                    0.974487   \n",
        "11                                    0.833417   \n",
        "\n",
        "    Random Forest Classifier (n_estimator=250)  \\\n",
        "0                                     0.993689   \n",
        "1                                     0.922956   \n",
        "2                                     0.973849   \n",
        "3                                     0.970296   \n",
        "4                                     0.971535   \n",
        "5                                     0.969877   \n",
        "6                                     0.974508   \n",
        "7                                     0.987504   \n",
        "8                                     0.990197   \n",
        "9                                     0.989668   \n",
        "10                                    0.974408   \n",
        "11                                    0.833417   \n",
        "\n",
        "    Random Forest Classifier (n_estimator=300)  \\\n",
        "0                                     0.992762   \n",
        "1                                     0.941725   \n",
        "2                                     0.969104   \n",
        "3                                     0.974868   \n",
        "4                                     0.971396   \n",
        "5                                     0.971009   \n",
        "6                                     0.977119   \n",
        "7                                     0.988761   \n",
        "8                                     0.990580   \n",
        "9                                     0.990724   \n",
        "10                                    0.976805   \n",
        "11                                    0.847006   \n",
        "\n",
        "    Random Forest Classifier (n_estimator=350)  \\\n",
        "0                                     0.988940   \n",
        "1                                     0.924774   \n",
        "2                                     0.969353   \n",
        "3                                     0.971187   \n",
        "4                                     0.970677   \n",
        "5                                     0.966762   \n",
        "6                                     0.973669   \n",
        "7                                     0.987165   \n",
        "8                                     0.989070   \n",
        "9                                     0.988273   \n",
        "10                                    0.972987   \n",
        "11                                    0.835430   \n",
        "\n",
        "    Random Forest Classifier (n_estimator=400)  \\\n",
        "0                                     0.993361   \n",
        "1                                     0.927099   \n",
        "2                                     0.974457   \n",
        "3                                     0.976677   \n",
        "4                                     0.973456   \n",
        "5                                     0.968252   \n",
        "6                                     0.977069   \n",
        "7                                     0.989087   \n",
        "8                                     0.990375   \n",
        "9                                     0.990569   \n",
        "10                                    0.976040   \n",
        "11                                    0.832914   \n",
        "\n",
        "                         ...                        \\\n",
        "0                        ...                         \n",
        "1                        ...                         \n",
        "2                        ...                         \n",
        "3                        ...                         \n",
        "4                        ...                         \n",
        "5                        ...                         \n",
        "6                        ...                         \n",
        "7                        ...                         \n",
        "8                        ...                         \n",
        "9                        ...                         \n",
        "10                       ...                         \n",
        "11                       ...                         \n",
        "\n",
        "    Decision Tree Classifier (criterion=entropy, min_samples_split=20, max_depth=10, min_samples_leaf=10, max_leaf_nodes=10)  \\\n",
        "0                                            0.898260                                                                          \n",
        "1                                            0.832577                                                                          \n",
        "2                                            0.823393                                                                          \n",
        "3                                            0.813888                                                                          \n",
        "4                                            0.885115                                                                          \n",
        "5                                            0.795765                                                                          \n",
        "6                                            0.843265                                                                          \n",
        "7                                            0.690112                                                                          \n",
        "8                                            0.817113                                                                          \n",
        "9                                            0.837015                                                                          \n",
        "10                                           0.823650                                                                          \n",
        "11                                           0.384499                                                                          \n",
        "\n",
        "    Decision Tree Classifier (criterion=entropy, min_samples_split=20, max_depth=10, min_samples_leaf=10, max_leaf_nodes=20)  \\\n",
        "0                                            0.949773                                                                          \n",
        "1                                            0.893102                                                                          \n",
        "2                                            0.905480                                                                          \n",
        "3                                            0.900802                                                                          \n",
        "4                                            0.936381                                                                          \n",
        "5                                            0.874392                                                                          \n",
        "6                                            0.958637                                                                          \n",
        "7                                            0.918442                                                                          \n",
        "8                                            0.938582                                                                          \n",
        "9                                            0.942484                                                                          \n",
        "10                                           0.921807                                                                          \n",
        "11                                           0.571213                                                                          \n",
        "\n",
        "    Best Decision Tree Classifier (criterion=entropy, min_samples_split=2, max_depth=None, min_samples_leaf=1, max_leaf_nodes=None)  \\\n",
        "0                                            0.965098                                                                                 \n",
        "1                                            0.901925                                                                                 \n",
        "2                                            0.979359                                                                                 \n",
        "3                                            0.957493                                                                                 \n",
        "4                                            0.977268                                                                                 \n",
        "5                                            0.985308                                                                                 \n",
        "6                                            0.989443                                                                                 \n",
        "7                                            0.987658                                                                                 \n",
        "8                                            0.999673                                                                                 \n",
        "9                                            0.995761                                                                                 \n",
        "10                                           0.973899                                                                                 \n",
        "11                                           0.972823                                                                                 \n",
        "\n",
        "    Logistic Regression (C=0.1)  Logistic Regression (C=1)  \\\n",
        "0                      0.450795                   0.450795   \n",
        "1                      0.534473                   0.534473   \n",
        "2                      0.585344                   0.585344   \n",
        "3                      0.519230                   0.519230   \n",
        "4                      0.491515                   0.491515   \n",
        "5                      0.470888                   0.470888   \n",
        "6                      0.507250                   0.507250   \n",
        "7                      0.511605                   0.511605   \n",
        "8                      0.543008                   0.543008   \n",
        "9                      0.479785                   0.479785   \n",
        "10                     0.509389                   0.509389   \n",
        "11                     0.230498                   0.230498   \n",
        "\n",
        "    Logistic Regression (C=10)  Logistic Regression (C=100)  \\\n",
        "0                     0.450795                     0.450795   \n",
        "1                     0.534473                     0.534473   \n",
        "2                     0.585344                     0.585344   \n",
        "3                     0.519230                     0.519230   \n",
        "4                     0.491515                     0.491515   \n",
        "5                     0.470888                     0.470888   \n",
        "6                     0.507250                     0.507250   \n",
        "7                     0.511605                     0.511605   \n",
        "8                     0.543008                     0.543008   \n",
        "9                     0.479785                     0.479785   \n",
        "10                    0.509389                     0.509389   \n",
        "11                    0.230498                     0.230498   \n",
        "\n",
        "    Logistic Regression (C=1000)  Best Logistic Regression (C=0.1)  \\\n",
        "0                       0.450795                          0.450795   \n",
        "1                       0.534473                          0.534473   \n",
        "2                       0.585344                          0.585344   \n",
        "3                       0.519230                          0.519230   \n",
        "4                       0.491515                          0.491515   \n",
        "5                       0.470888                          0.470888   \n",
        "6                       0.507250                          0.507250   \n",
        "7                       0.511605                          0.511605   \n",
        "8                       0.543008                          0.543008   \n",
        "9                       0.479785                          0.479785   \n",
        "10                      0.509389                          0.509389   \n",
        "11                      0.230498                          0.230498   \n",
        "\n",
        "    Best Gradient Boosting Classifier (kernel=rbf)  \n",
        "0                                         0.998870  \n",
        "1                                         0.928998  \n",
        "2                                         0.988991  \n",
        "3                                         0.983775  \n",
        "4                                         0.992001  \n",
        "5                                         0.997386  \n",
        "6                                         0.995595  \n",
        "7                                         0.995521  \n",
        "8                                         0.998788  \n",
        "9                                         0.996628  \n",
        "10                                        0.987655  \n",
        "11                                        0.950176  \n",
        "\n",
        "[12 rows x 310 columns]"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "heading",
     "level": 7,
     "metadata": {},
     "source": [
      "As result, we have AUC, medium AUC and Accuracy values of 315 training test models. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "6. Write best results to file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "BestRoc = pd.DataFrame()\n",
      "BestRoc[\"roc of\"]=[0,2,3,4,5,6,7,8,9,10,'medium','Accuracy']\n",
      "BestRoc[\"Random Forest Classifier\"] = rocRFC+[medium(rocRFC)]+[accuracy_score(ytest, ypredRFC)]\n",
      "BestRoc[\"SVM\"] = rocSVM+[medium(rocSVM)]+[accuracy_score(ytest, ypredSVM)]\n",
      "BestRoc[\"Decision Tree Classifier\"] = rocDTC+[medium(rocDTC)]+[accuracy_score(ytest, ypredDTC)]\n",
      "BestRoc[\"Logistic Regression\"] = rocLogReg+[medium(rocLogReg)]+[accuracy_score(ytest, ypredLogReg)]\n",
      "BestRoc[\"Gradient Boosting Classifier\"] = rocGBC+[medium(rocGBC)]+[accuracy_score(ytest, ypredGBC)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# Adding in resulting file AUC and Accuracy initial model\n",
      "dlf = RandomForestClassifier(n_estimators=200, random_state=0)\n",
      "dlf.fit(Xtrain, ytrain)\n",
      "ypred = dlf.predict(Xtest)\n",
      "roc = get_roc(dlf,Xtrain,ytrain,Xtest, ytest)\n",
      "BestRoc[\"Initial model Random Forest Classifier (n_estimators=200, random_state=0)\"]=roc+[medium(roc)]+[accuracy_score(ytest, ypred)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "BestRoc.to_csv(\"Roc of best models.csv\", index=False)\n",
      "BestRoc[:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div>\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>roc of</th>\n",
        "      <th>Random Forest Classifier</th>\n",
        "      <th>SVM</th>\n",
        "      <th>Decision Tree Classifier</th>\n",
        "      <th>Logistic Regression</th>\n",
        "      <th>Gradient Boosting Classifier</th>\n",
        "      <th>Initial model Random Forest Classifier (n_estimators=200, random_state=0)</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>0</td>\n",
        "      <td>0.991524</td>\n",
        "      <td>0.632486</td>\n",
        "      <td>0.965098</td>\n",
        "      <td>0.450795</td>\n",
        "      <td>0.998870</td>\n",
        "      <td>0.989498</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>2</td>\n",
        "      <td>0.939457</td>\n",
        "      <td>0.560737</td>\n",
        "      <td>0.901925</td>\n",
        "      <td>0.534473</td>\n",
        "      <td>0.928998</td>\n",
        "      <td>0.903110</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>3</td>\n",
        "      <td>0.971763</td>\n",
        "      <td>0.549258</td>\n",
        "      <td>0.979359</td>\n",
        "      <td>0.585344</td>\n",
        "      <td>0.988991</td>\n",
        "      <td>0.967231</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>4</td>\n",
        "      <td>0.972488</td>\n",
        "      <td>0.583208</td>\n",
        "      <td>0.957493</td>\n",
        "      <td>0.519230</td>\n",
        "      <td>0.983775</td>\n",
        "      <td>0.972814</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>5</td>\n",
        "      <td>0.970301</td>\n",
        "      <td>0.579531</td>\n",
        "      <td>0.977268</td>\n",
        "      <td>0.491515</td>\n",
        "      <td>0.992001</td>\n",
        "      <td>0.970645</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td>6</td>\n",
        "      <td>0.967266</td>\n",
        "      <td>0.539025</td>\n",
        "      <td>0.985308</td>\n",
        "      <td>0.470888</td>\n",
        "      <td>0.997386</td>\n",
        "      <td>0.968776</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td>7</td>\n",
        "      <td>0.974863</td>\n",
        "      <td>0.546831</td>\n",
        "      <td>0.989443</td>\n",
        "      <td>0.507250</td>\n",
        "      <td>0.995595</td>\n",
        "      <td>0.976171</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7</th>\n",
        "      <td>8</td>\n",
        "      <td>0.987698</td>\n",
        "      <td>0.554933</td>\n",
        "      <td>0.987658</td>\n",
        "      <td>0.511605</td>\n",
        "      <td>0.995521</td>\n",
        "      <td>0.987331</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8</th>\n",
        "      <td>9</td>\n",
        "      <td>0.988833</td>\n",
        "      <td>0.597124</td>\n",
        "      <td>0.999673</td>\n",
        "      <td>0.543008</td>\n",
        "      <td>0.998788</td>\n",
        "      <td>0.988835</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9</th>\n",
        "      <td>10</td>\n",
        "      <td>0.989513</td>\n",
        "      <td>0.519885</td>\n",
        "      <td>0.995761</td>\n",
        "      <td>0.479785</td>\n",
        "      <td>0.996628</td>\n",
        "      <td>0.990045</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td>medium</td>\n",
        "      <td>0.975371</td>\n",
        "      <td>0.566302</td>\n",
        "      <td>0.973899</td>\n",
        "      <td>0.509389</td>\n",
        "      <td>0.987655</td>\n",
        "      <td>0.971446</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td>Accuracy</td>\n",
        "      <td>0.832411</td>\n",
        "      <td>0.237041</td>\n",
        "      <td>0.972823</td>\n",
        "      <td>0.230498</td>\n",
        "      <td>0.950176</td>\n",
        "      <td>0.834927</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "      roc of  Random Forest Classifier       SVM  Decision Tree Classifier  \\\n",
        "0          0                  0.991524  0.632486                  0.965098   \n",
        "1          2                  0.939457  0.560737                  0.901925   \n",
        "2          3                  0.971763  0.549258                  0.979359   \n",
        "3          4                  0.972488  0.583208                  0.957493   \n",
        "4          5                  0.970301  0.579531                  0.977268   \n",
        "5          6                  0.967266  0.539025                  0.985308   \n",
        "6          7                  0.974863  0.546831                  0.989443   \n",
        "7          8                  0.987698  0.554933                  0.987658   \n",
        "8          9                  0.988833  0.597124                  0.999673   \n",
        "9         10                  0.989513  0.519885                  0.995761   \n",
        "10    medium                  0.975371  0.566302                  0.973899   \n",
        "11  Accuracy                  0.832411  0.237041                  0.972823   \n",
        "\n",
        "    Logistic Regression  Gradient Boosting Classifier  \\\n",
        "0              0.450795                      0.998870   \n",
        "1              0.534473                      0.928998   \n",
        "2              0.585344                      0.988991   \n",
        "3              0.519230                      0.983775   \n",
        "4              0.491515                      0.992001   \n",
        "5              0.470888                      0.997386   \n",
        "6              0.507250                      0.995595   \n",
        "7              0.511605                      0.995521   \n",
        "8              0.543008                      0.998788   \n",
        "9              0.479785                      0.996628   \n",
        "10             0.509389                      0.987655   \n",
        "11             0.230498                      0.950176   \n",
        "\n",
        "    Initial model Random Forest Classifier (n_estimators=200, random_state=0)  \n",
        "0                                            0.989498                          \n",
        "1                                            0.903110                          \n",
        "2                                            0.967231                          \n",
        "3                                            0.972814                          \n",
        "4                                            0.970645                          \n",
        "5                                            0.968776                          \n",
        "6                                            0.976171                          \n",
        "7                                            0.987331                          \n",
        "8                                            0.988835                          \n",
        "9                                            0.990045                          \n",
        "10                                           0.971446                          \n",
        "11                                           0.834927                          "
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "\n",
      "For easier search best result we applied GridSearchCV. As we can see Gradient Boosting Classifier getting best result for AUC and very good for Accuracy (little wourse then Decision Tree Classifier). \n",
      "\n",
      "However Decision Tree Classifier getting best result for Accuracy and little worse result for AUS then Gradient Boosting Classifier. \n",
      "\n",
      "In the middle this two methods very good, but Decision Tree Classifier have less difference betwen medium AUC and Accuracy then Gradient Boosting Classifier. That's why Decision Tree Classifier better than Gradient Boosting Classifier.\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "7. Write prediction file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred = pd.DataFrame()\n",
      "pred[\"# Age vs Job\"] = ytest\n",
      "pred[\"Prediction Random Forest Classifier\"] = ypredRFC\n",
      "pred[\"Prediction SVM\"] = ypredSVM\n",
      "pred[\"Prediction Decision Tree Classifier\"] = ypredDTC\n",
      "pred[\"Prediction Logistic Regression\"] = ypredLogReg\n",
      "pred[\"Prediction Gradient Boosting Classifier\"] = ypredGBC\n",
      "pred.to_csv(\"Prediction Age vs Job.csv\", index=False)\n",
      "pred[:30]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div>\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th># Age vs Job</th>\n",
        "      <th>Prediction Random Forest Classifier</th>\n",
        "      <th>Prediction SVM</th>\n",
        "      <th>Prediction Decision Tree Classifier</th>\n",
        "      <th>Prediction Logistic Regression</th>\n",
        "      <th>Prediction Gradient Boosting Classifier</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>9</td>\n",
        "      <td>9</td>\n",
        "      <td>9</td>\n",
        "      <td>9</td>\n",
        "      <td>8</td>\n",
        "      <td>9</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>9</td>\n",
        "      <td>9</td>\n",
        "      <td>8</td>\n",
        "      <td>9</td>\n",
        "      <td>9</td>\n",
        "      <td>9</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>9</td>\n",
        "      <td>9</td>\n",
        "      <td>8</td>\n",
        "      <td>9</td>\n",
        "      <td>9</td>\n",
        "      <td>9</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>7</td>\n",
        "      <td>7</td>\n",
        "      <td>8</td>\n",
        "      <td>7</td>\n",
        "      <td>8</td>\n",
        "      <td>7</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>9</td>\n",
        "      <td>9</td>\n",
        "      <td>8</td>\n",
        "      <td>9</td>\n",
        "      <td>8</td>\n",
        "      <td>9</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td>8</td>\n",
        "      <td>8</td>\n",
        "      <td>8</td>\n",
        "      <td>8</td>\n",
        "      <td>8</td>\n",
        "      <td>8</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td>5</td>\n",
        "      <td>5</td>\n",
        "      <td>8</td>\n",
        "      <td>5</td>\n",
        "      <td>8</td>\n",
        "      <td>5</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7</th>\n",
        "      <td>9</td>\n",
        "      <td>9</td>\n",
        "      <td>8</td>\n",
        "      <td>9</td>\n",
        "      <td>8</td>\n",
        "      <td>9</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8</th>\n",
        "      <td>9</td>\n",
        "      <td>9</td>\n",
        "      <td>8</td>\n",
        "      <td>9</td>\n",
        "      <td>8</td>\n",
        "      <td>9</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9</th>\n",
        "      <td>4</td>\n",
        "      <td>8</td>\n",
        "      <td>8</td>\n",
        "      <td>4</td>\n",
        "      <td>8</td>\n",
        "      <td>4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td>5</td>\n",
        "      <td>5</td>\n",
        "      <td>8</td>\n",
        "      <td>5</td>\n",
        "      <td>9</td>\n",
        "      <td>5</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td>3</td>\n",
        "      <td>3</td>\n",
        "      <td>8</td>\n",
        "      <td>3</td>\n",
        "      <td>8</td>\n",
        "      <td>3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td>6</td>\n",
        "      <td>6</td>\n",
        "      <td>8</td>\n",
        "      <td>6</td>\n",
        "      <td>9</td>\n",
        "      <td>6</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td>8</td>\n",
        "      <td>8</td>\n",
        "      <td>8</td>\n",
        "      <td>8</td>\n",
        "      <td>8</td>\n",
        "      <td>8</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td>8</td>\n",
        "      <td>8</td>\n",
        "      <td>8</td>\n",
        "      <td>8</td>\n",
        "      <td>8</td>\n",
        "      <td>8</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td>7</td>\n",
        "      <td>7</td>\n",
        "      <td>8</td>\n",
        "      <td>7</td>\n",
        "      <td>8</td>\n",
        "      <td>7</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td>5</td>\n",
        "      <td>5</td>\n",
        "      <td>8</td>\n",
        "      <td>5</td>\n",
        "      <td>8</td>\n",
        "      <td>5</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td>9</td>\n",
        "      <td>9</td>\n",
        "      <td>8</td>\n",
        "      <td>9</td>\n",
        "      <td>9</td>\n",
        "      <td>9</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18</th>\n",
        "      <td>8</td>\n",
        "      <td>8</td>\n",
        "      <td>8</td>\n",
        "      <td>8</td>\n",
        "      <td>8</td>\n",
        "      <td>8</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19</th>\n",
        "      <td>8</td>\n",
        "      <td>8</td>\n",
        "      <td>8</td>\n",
        "      <td>8</td>\n",
        "      <td>9</td>\n",
        "      <td>8</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20</th>\n",
        "      <td>7</td>\n",
        "      <td>7</td>\n",
        "      <td>8</td>\n",
        "      <td>7</td>\n",
        "      <td>9</td>\n",
        "      <td>7</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21</th>\n",
        "      <td>9</td>\n",
        "      <td>10</td>\n",
        "      <td>8</td>\n",
        "      <td>9</td>\n",
        "      <td>8</td>\n",
        "      <td>9</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22</th>\n",
        "      <td>5</td>\n",
        "      <td>5</td>\n",
        "      <td>8</td>\n",
        "      <td>5</td>\n",
        "      <td>9</td>\n",
        "      <td>5</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>23</th>\n",
        "      <td>5</td>\n",
        "      <td>5</td>\n",
        "      <td>8</td>\n",
        "      <td>5</td>\n",
        "      <td>9</td>\n",
        "      <td>5</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>24</th>\n",
        "      <td>4</td>\n",
        "      <td>4</td>\n",
        "      <td>8</td>\n",
        "      <td>4</td>\n",
        "      <td>8</td>\n",
        "      <td>4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25</th>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>8</td>\n",
        "      <td>0</td>\n",
        "      <td>8</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>26</th>\n",
        "      <td>8</td>\n",
        "      <td>8</td>\n",
        "      <td>8</td>\n",
        "      <td>1</td>\n",
        "      <td>8</td>\n",
        "      <td>8</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27</th>\n",
        "      <td>8</td>\n",
        "      <td>8</td>\n",
        "      <td>8</td>\n",
        "      <td>8</td>\n",
        "      <td>8</td>\n",
        "      <td>8</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>28</th>\n",
        "      <td>9</td>\n",
        "      <td>9</td>\n",
        "      <td>8</td>\n",
        "      <td>9</td>\n",
        "      <td>9</td>\n",
        "      <td>9</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>29</th>\n",
        "      <td>10</td>\n",
        "      <td>10</td>\n",
        "      <td>8</td>\n",
        "      <td>10</td>\n",
        "      <td>9</td>\n",
        "      <td>10</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "    # Age vs Job  Prediction Random Forest Classifier  Prediction SVM  \\\n",
        "0              9                                    9               9   \n",
        "1              9                                    9               8   \n",
        "2              9                                    9               8   \n",
        "3              7                                    7               8   \n",
        "4              9                                    9               8   \n",
        "5              8                                    8               8   \n",
        "6              5                                    5               8   \n",
        "7              9                                    9               8   \n",
        "8              9                                    9               8   \n",
        "9              4                                    8               8   \n",
        "10             5                                    5               8   \n",
        "11             3                                    3               8   \n",
        "12             6                                    6               8   \n",
        "13             8                                    8               8   \n",
        "14             8                                    8               8   \n",
        "15             7                                    7               8   \n",
        "16             5                                    5               8   \n",
        "17             9                                    9               8   \n",
        "18             8                                    8               8   \n",
        "19             8                                    8               8   \n",
        "20             7                                    7               8   \n",
        "21             9                                   10               8   \n",
        "22             5                                    5               8   \n",
        "23             5                                    5               8   \n",
        "24             4                                    4               8   \n",
        "25             0                                    0               8   \n",
        "26             8                                    8               8   \n",
        "27             8                                    8               8   \n",
        "28             9                                    9               8   \n",
        "29            10                                   10               8   \n",
        "\n",
        "    Prediction Decision Tree Classifier  Prediction Logistic Regression  \\\n",
        "0                                     9                               8   \n",
        "1                                     9                               9   \n",
        "2                                     9                               9   \n",
        "3                                     7                               8   \n",
        "4                                     9                               8   \n",
        "5                                     8                               8   \n",
        "6                                     5                               8   \n",
        "7                                     9                               8   \n",
        "8                                     9                               8   \n",
        "9                                     4                               8   \n",
        "10                                    5                               9   \n",
        "11                                    3                               8   \n",
        "12                                    6                               9   \n",
        "13                                    8                               8   \n",
        "14                                    8                               8   \n",
        "15                                    7                               8   \n",
        "16                                    5                               8   \n",
        "17                                    9                               9   \n",
        "18                                    8                               8   \n",
        "19                                    8                               9   \n",
        "20                                    7                               9   \n",
        "21                                    9                               8   \n",
        "22                                    5                               9   \n",
        "23                                    5                               9   \n",
        "24                                    4                               8   \n",
        "25                                    0                               8   \n",
        "26                                    1                               8   \n",
        "27                                    8                               8   \n",
        "28                                    9                               9   \n",
        "29                                   10                               9   \n",
        "\n",
        "    Prediction Gradient Boosting Classifier  \n",
        "0                                         9  \n",
        "1                                         9  \n",
        "2                                         9  \n",
        "3                                         7  \n",
        "4                                         9  \n",
        "5                                         8  \n",
        "6                                         5  \n",
        "7                                         9  \n",
        "8                                         9  \n",
        "9                                         4  \n",
        "10                                        5  \n",
        "11                                        3  \n",
        "12                                        6  \n",
        "13                                        8  \n",
        "14                                        8  \n",
        "15                                        7  \n",
        "16                                        5  \n",
        "17                                        9  \n",
        "18                                        8  \n",
        "19                                        8  \n",
        "20                                        7  \n",
        "21                                        9  \n",
        "22                                        5  \n",
        "23                                        5  \n",
        "24                                        4  \n",
        "25                                        0  \n",
        "26                                        8  \n",
        "27                                        8  \n",
        "28                                        9  \n",
        "29                                       10  "
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "8. Write common results file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_result = pd.DataFrame(Xtest, columns=[\"# Count Factors\",\"# Customers vs Account\",\"# Customers vs Job\",\n",
      "                                         \"# Industries vs Account\",\"# Industries vs Job\",\"# Loyalty vs Account\",\n",
      "                                         \"# Pedigree vs Account\",\"# Roles vs Job\",\"# University vs Account\",\"% Loyalty vs Team\",\n",
      "                                         \"% Loyalty vs Universe\",\"% Pedigree vs Team\",\"% Pedigree vs Universe\",\n",
      "                                         \"% University vs Team\",\"% University vs Universe\",\"+ Position Tenure (Months)\",\n",
      "                                         \"Job Experience (Years)\",\"Deviation Denominator (Years)\",\"Lion Experience Total\",\n",
      "                                         \"Lion Experience Role\",\"Lion Experience Industry\",\n",
      "                                         \"Lion Experience Industry (Weighted)\",\"Lion Experience Customer\",\n",
      "                                         \"Lion Experience Customer (Weighted)\",\"Introduction (Tracker): # Weeks Alive\",\n",
      "                                         \"Introduction (Tracker): Date to Screened\",\"Introduction (Tracker): Date to Hired\",\n",
      "                                         \"Introduction to Screen?\",\"Introduction to Meeting?\",\"Introduction to Offer?\",\n",
      "                                         \"Introduction to Hire?\",\"Introduction Alive 3 Weeks?\",\"DO NOT USE (Match Failed?)\"])\n",
      "df_result[\"# Age vs Job\"] = ytest\n",
      "df_result[\"Prediction Random Forest Classifier\"] = ypredRFC\n",
      "df_result[\"Prediction SVM\"] = ypredSVM\n",
      "df_result[\"Prediction Decision Tree Classifier\"] = ypredDTC\n",
      "df_result[\"Prediction Logistic Regression\"] = ypredLogReg\n",
      "df_result[\"Prediction Gradient Boosting Classifier\"] = ypredGBC\n",
      "df_result.to_csv(\"Prediction Age vs Job all.csv\", index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "We was  able to predict the values from 'Age vs Job ' column with "
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "max AUC =  0.987655"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "max Accuracy = 0.972823"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Comparison with previous results"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Initial model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dlf = RandomForestClassifier(n_estimators=200, random_state=0)\n",
      "dlf.fit(Xtrain, ytrain)\n",
      "ypred = dlf.predict(Xtest)\n",
      "\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "scores = cross_val_score(dlf, X, y)\n",
      "rocDTC = get_roc(dlf,Xtrain,ytrain,Xtest, ytest)\n",
      "acc = accuracy_score(ytest, ypred)\n",
      "\n",
      "print 'Cross validation score: ', scores.mean()\n",
      "print 'Accuracy: ', acc\n",
      "print 'AUC: ', medium(rocDTC)\n",
      "print dlf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Cross validation score:  0.720884392937\n",
        "Accuracy:  0.818822345244\n",
        "AUC:  0.9755099549\n",
        "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
        "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
        "            min_samples_leaf=1, min_samples_split=2,\n",
        "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
        "            oob_score=False, random_state=0, verbose=0, warm_start=False)\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "The best model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Calculation best combination of parameters\n",
      "paramDTC = {\"criterion\": [\"gini\", \"entropy\"],\n",
      "            \"min_samples_split\": [2, 10, 20],\n",
      "            \"max_depth\": [None, 2, 5, 10],\n",
      "            \"min_samples_leaf\": [1, 5, 10],\n",
      "            \"max_leaf_nodes\": [None, 5, 10, 20]}\n",
      "model = DecisionTreeClassifier()\n",
      "gridDTC = GridSearchCV(model, param_grid=paramDTC)\n",
      "clfDTC = gridDTC.fit(Xtrain, ytrain)\n",
      "best_criterion=clfDTC.best_estimator_.criterion\n",
      "best_min_samples_split=clfDTC.best_estimator_.min_samples_split\n",
      "best_max_depth=clfDTC.best_estimator_.max_depth\n",
      "best_min_samples_leaf=clfDTC.best_estimator_.min_samples_leaf\n",
      "best_max_leaf_nodes=clfDTC.best_estimator_.max_leaf_nodes\n",
      "\n",
      "# Training classifier for best parameters and getting prediction\n",
      "clfDTC = DecisionTreeClassifier(criterion=best_criterion,\n",
      "                                min_samples_split=best_min_samples_split,\n",
      "                                max_depth=best_max_depth,\n",
      "                                min_samples_leaf=best_min_samples_leaf,\n",
      "                                max_leaf_nodes=best_max_leaf_nodes)\n",
      "clfDTC.fit(Xtrain, ytrain)\n",
      "ypredDTC = clfDTC.predict(Xtest)\n",
      "\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "scores = cross_val_score(clfDTC, X, y)\n",
      "rocDTC = get_roc(clfDTC,Xtrain,ytrain,Xtest, ytest)\n",
      "acc = accuracy_score(ytest, ypredDTC)\n",
      "\n",
      "print 'Cross validation score: ', scores.mean()\n",
      "print 'Accuracy: ', acc\n",
      "print 'AUC: ', medium(rocDTC)\n",
      "print clfDTC"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Cross validation score:  0.96677212727\n",
        "Accuracy:  0.981882234524\n",
        "AUC:  0.984839542698\n",
        "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
        "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
        "            random_state=None, splitter='best')\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Result"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "We was able to improve initial model \n",
      "\n",
      "RandomForestClassifier(n_estimators=200, random_state=0)\n",
      "\n",
      "\n",
      "with the best model\n",
      "\n",
      "DecisionTreeClassifier(criterion='entropy', min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            random_state=None, splitter='best')\n",
      "\n",
      "\n",
      "in such values:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                        Initial  model     Result model         Diff\n",
      "        \n",
      "Cross validation score: 0.7208              0.9667               25 %\n",
      "Accuracy:               0.8188              0.9819               16 %\n",
      "AUC:                    0.9755              0.9848               1 %"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}